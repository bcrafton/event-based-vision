
a smaller network with random weights actually works well
big problem is we are double boxing literally everything

~0.5 loss was corresponding to pretty much perfect accuracy, BUT we are double boxing everything.

something is up with obj/no_obj tho
because its usually a 50-50 split
and the loss is 0.5
AND we have double boxes.

total: 1392, rate: 33.584092, loss 0.495076 (7 0 53 38 0)

------

what about just a single box ? 

------

there is def something wrong with calc_map i think.

------

dataset_visualization literally loads every file in the list
just make it not do that 
and we shud be good

------

overfitting.

> starting with actual DNN.
  > not training it tranferred layers

> image augmentation

------

wrote a bunch of notes on loader changes:

basically:
dataset, load

load diverged from dataset at ' update design notes '
meaning only real changes are:
https://github.com/bcrafton/event-based-vision/commits/load
https://github.com/bcrafton/event-based-vision/commit/e01c12188f519fc38a4e7148023df97c8a7fdfed#diff-e44f4a60e89e820dde9bb27afa634965

------

> load.py
> train.py
> dataset_visualization.py

------




































